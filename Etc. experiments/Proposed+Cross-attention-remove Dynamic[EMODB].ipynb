{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from silence_tensorflow import silence_tensorflow\n",
    "silence_tensorflow()\n",
    "\n",
    "from tensorflow.keras.layers import Layer, Lambda, Conv2D, Dropout,Dense,Activation,Input,GlobalAveragePooling1D, Concatenate, GlobalAveragePooling2D, LayerNormalization, MaxPool2D\n",
    "from tensorflow.keras.layers import Reshape,Flatten,BatchNormalization,MaxPooling1D,AveragePooling2D,Reshape,Attention, ReLU, Activation, SpatialDropout2D, DepthwiseConv2D\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras import regularizers\n",
    "from sklearn.model_selection import KFold\n",
    "import keras.backend as K\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tqdm.auto import tqdm\n",
    "import os\n",
    "from Config import Config\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.metrics import Mean, CategoricalAccuracy\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
    "from datetime import datetime\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy, MeanSquaredError\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.config.run_functions_eagerly(True)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('always')\n",
    "\n",
    "from my_models import *\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ROOT = 'TIMNET-dataset'\n",
    "DATA_PATH = 'EMODB'\n",
    "CLASS_LABELS = Config.EMODB_LABELS\n",
    "k = 10\n",
    "\n",
    "model_name = 'exp1-remove Dynamic-routing'\n",
    "feature_name = 'mfcc'\n",
    "\n",
    "learning_rate=0.001\n",
    "beta_1=0.975\n",
    "beta_2=0.932\n",
    "epsilon=1e-8\n",
    "\n",
    "EPOCHS = 300\n",
    "BATCH = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class removeDWSCNN(tf.keras.Model):\n",
    "\n",
    "  def __init__(self, dim_capsule=64, n_channels=6, kernel_size=3, strides=1, padding='valid'):\n",
    "    super().__init__()\n",
    "    \n",
    "    self.layer = Sequential([\n",
    "        Reshape(target_shape=[-1, dim_capsule]),\n",
    "        Lambda(function=PrimaryCapssquash)\n",
    "    ])\n",
    "    \n",
    "  def call(self, inputs):\n",
    "    return self.layer(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(tf.keras.Model):\n",
    "\n",
    "  def __init__(self, num_classes):\n",
    "    super().__init__()\n",
    "    \n",
    "    self.conv1 = Sequential([\n",
    "      Conv2D(filters=64, kernel_size=3),\n",
    "      BatchNormalization(axis=1),\n",
    "      Activation('elu'),\n",
    "      AveragePooling2D(),\n",
    "      SpatialDropout2D(0.2)\n",
    "    ])\n",
    "    \n",
    "    self.conv2 = Sequential([\n",
    "      Conv2D(filters=64, kernel_size=3),\n",
    "      BatchNormalization(axis=1),\n",
    "      Activation('elu'),\n",
    "      AveragePooling2D(),\n",
    "      SpatialDropout2D(0.2),\n",
    "    ])\n",
    "    \n",
    "    self.conv3 = Sequential([\n",
    "      Conv2D(filters=64, kernel_size=3, dilation_rate=2),\n",
    "      BatchNormalization(axis=1),\n",
    "      Activation('elu'),\n",
    "      AveragePooling2D(),\n",
    "      SpatialDropout2D(0.2),\n",
    "    ])\n",
    "  \n",
    "    # Q, V, K\n",
    "    self.attention = Attention(use_scale=True)\n",
    "    self.LN = LayerNormalization()\n",
    "    self.lamb = Lambda(lambda x: tf.multiply(x[0], x[1]))\n",
    "    \n",
    "    self.cbam = CBAM(64) # sharing\n",
    "    self.reshape = Reshape(target_shape=[-1, 64])\n",
    "    \n",
    "    self.conv4 = PrimaryCap()\n",
    "    self.spatial_attn = SpatialGate()\n",
    "  \n",
    "    self.gap = GlobalAveragePooling1D()\n",
    "    self.dropout = Dropout(0.2)\n",
    "    self.classifier = Dense(num_classes, activation='softmax')\n",
    "    \n",
    "    \n",
    "  def call(self, inputs):\n",
    "    x = inputs\n",
    "    forward = x\n",
    "    backward = tf.reverse(inputs, axis=[2])\n",
    "    \n",
    "    fx = self.conv1(forward)\n",
    "    fx += self.cbam(fx)\n",
    "    bx = self.conv2(backward)\n",
    "    bx += self.cbam(bx)\n",
    "    cross_attn_out = self.attention([fx, bx, bx]) # Q, K==V\n",
    "    fx += cross_attn_out\n",
    "    \n",
    "    fx = self.conv3(fx)\n",
    "    fx += self.cbam(fx)\n",
    "    \n",
    "    cap = self.conv4(fx)\n",
    "    cap = tf.expand_dims(cap, axis=-1)\n",
    "    cap += self.spatial_attn(cap)\n",
    "    cap = tf.squeeze(cap, axis=-1)\n",
    "    \n",
    "    sa = self.attention([cap, cap, cap])\n",
    "    sa = self.LN(sa)\n",
    "    \n",
    "    sa = self.lamb([cap, sa])\n",
    "    sa = tf.expand_dims(sa, axis=-1)\n",
    "    sa += self.spatial_attn(sa)\n",
    "    sa = tf.squeeze(sa, axis=-1)\n",
    "    \n",
    "    gap = self.gap(sa)\n",
    "    drop = self.dropout(gap)\n",
    "    \n",
    "    output_softmax = self.classifier(drop)\n",
    "    return output_softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input 0 of layer \"global_average_pooling1d\" is incompatible with the layer: expected ndim=3, found ndim=4. Full shape received: (None, 1320, 64, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\devLupin\\현재 진행\\★ 실험\\exp1-remove Dynamic[EMODB].ipynb Cell 6\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/devLupin/%ED%98%84%EC%9E%AC%20%EC%A7%84%ED%96%89/%E2%98%85%20%EC%8B%A4%ED%97%98/exp1-remove%20Dynamic%5BEMODB%5D.ipynb#W5sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model \u001b[39m=\u001b[39m Model(\u001b[39mlen\u001b[39m(CLASS_LABELS))\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/devLupin/%ED%98%84%EC%9E%AC%20%EC%A7%84%ED%96%89/%E2%98%85%20%EC%8B%A4%ED%97%98/exp1-remove%20Dynamic%5BEMODB%5D.ipynb#W5sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m model\u001b[39m.\u001b[39;49mbuild(input_shape\u001b[39m=\u001b[39;49m(\u001b[39mNone\u001b[39;49;00m, \u001b[39m196\u001b[39;49m, \u001b[39m39\u001b[39;49m, \u001b[39m1\u001b[39;49m))\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/devLupin/%ED%98%84%EC%9E%AC%20%EC%A7%84%ED%96%89/%E2%98%85%20%EC%8B%A4%ED%97%98/exp1-remove%20Dynamic%5BEMODB%5D.ipynb#W5sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m model\u001b[39m.\u001b[39msummary()\n",
      "File \u001b[1;32mc:\\Users\\devLupin\\Miniconda3\\envs\\ser-tf\\lib\\site-packages\\keras\\engine\\training.py:509\u001b[0m, in \u001b[0;36mModel.build\u001b[1;34m(self, input_shape)\u001b[0m\n\u001b[0;32m    504\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    505\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mYou can only call `build()` on a model if its \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    506\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m`call()` method accepts an `inputs` argument.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    507\u001b[0m     )\n\u001b[0;32m    508\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 509\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcall(x, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    510\u001b[0m \u001b[39mexcept\u001b[39;00m (tf\u001b[39m.\u001b[39merrors\u001b[39m.\u001b[39mInvalidArgumentError, \u001b[39mTypeError\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    511\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    512\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mYou cannot build your model by calling `build` \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    513\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mif your layers do not support float type inputs. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    517\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m`call` is: \u001b[39m\u001b[39m{\u001b[39;00me\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    518\u001b[0m     )\n",
      "\u001b[1;32mc:\\Users\\devLupin\\현재 진행\\★ 실험\\exp1-remove Dynamic[EMODB].ipynb Cell 6\u001b[0m line \u001b[0;36m7\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/devLupin/%ED%98%84%EC%9E%AC%20%EC%A7%84%ED%96%89/%E2%98%85%20%EC%8B%A4%ED%97%98/exp1-remove%20Dynamic%5BEMODB%5D.ipynb#W5sZmlsZQ%3D%3D?line=69'>70</a>\u001b[0m sa \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mexpand_dims(sa, axis\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/devLupin/%ED%98%84%EC%9E%AC%20%EC%A7%84%ED%96%89/%E2%98%85%20%EC%8B%A4%ED%97%98/exp1-remove%20Dynamic%5BEMODB%5D.ipynb#W5sZmlsZQ%3D%3D?line=70'>71</a>\u001b[0m sa \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mspatial_attn(sa)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/devLupin/%ED%98%84%EC%9E%AC%20%EC%A7%84%ED%96%89/%E2%98%85%20%EC%8B%A4%ED%97%98/exp1-remove%20Dynamic%5BEMODB%5D.ipynb#W5sZmlsZQ%3D%3D?line=72'>73</a>\u001b[0m gap \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgap(sa)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/devLupin/%ED%98%84%EC%9E%AC%20%EC%A7%84%ED%96%89/%E2%98%85%20%EC%8B%A4%ED%97%98/exp1-remove%20Dynamic%5BEMODB%5D.ipynb#W5sZmlsZQ%3D%3D?line=73'>74</a>\u001b[0m drop \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(gap)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/devLupin/%ED%98%84%EC%9E%AC%20%EC%A7%84%ED%96%89/%E2%98%85%20%EC%8B%A4%ED%97%98/exp1-remove%20Dynamic%5BEMODB%5D.ipynb#W5sZmlsZQ%3D%3D?line=75'>76</a>\u001b[0m output_softmax \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclassifier(drop)\n",
      "File \u001b[1;32mc:\\Users\\devLupin\\Miniconda3\\envs\\ser-tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\devLupin\\Miniconda3\\envs\\ser-tf\\lib\\site-packages\\keras\\engine\\input_spec.py:232\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[1;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[0;32m    230\u001b[0m     ndim \u001b[39m=\u001b[39m shape\u001b[39m.\u001b[39mrank\n\u001b[0;32m    231\u001b[0m     \u001b[39mif\u001b[39;00m ndim \u001b[39m!=\u001b[39m spec\u001b[39m.\u001b[39mndim:\n\u001b[1;32m--> 232\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    233\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mInput \u001b[39m\u001b[39m{\u001b[39;00minput_index\u001b[39m}\u001b[39;00m\u001b[39m of layer \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mlayer_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    234\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mis incompatible with the layer: \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    235\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mexpected ndim=\u001b[39m\u001b[39m{\u001b[39;00mspec\u001b[39m.\u001b[39mndim\u001b[39m}\u001b[39;00m\u001b[39m, found ndim=\u001b[39m\u001b[39m{\u001b[39;00mndim\u001b[39m}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    236\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFull shape received: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtuple\u001b[39m(shape)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    237\u001b[0m         )\n\u001b[0;32m    238\u001b[0m \u001b[39mif\u001b[39;00m spec\u001b[39m.\u001b[39mmax_ndim \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    239\u001b[0m     ndim \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mshape\u001b[39m.\u001b[39mrank\n",
      "\u001b[1;31mValueError\u001b[0m: Input 0 of layer \"global_average_pooling1d\" is incompatible with the layer: expected ndim=3, found ndim=4. Full shape received: (None, 1320, 64, 1)"
     ]
    }
   ],
   "source": [
    "model = Model(len(CLASS_LABELS))\n",
    "model.build(input_shape=(None, 196, 39, 1))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def margin_loss(y_true, y_pred):\n",
    "    \"\"\"\n",
    "        Margin Loss\n",
    "        :param y_true: [None, n_classes]\n",
    "        :param y_pred: [None, num_capsule]\n",
    "        :return: a scalar loss value.\n",
    "    \"\"\"\n",
    "    L = y_true * K.square(K.maximum(0., 0.9 - y_pred)) + \\\n",
    "        0.5 * (1 - y_true) * K.square(K.maximum(0., y_pred - 0.1))\n",
    "\n",
    "    return K.mean(K.sum(L, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(model, optimizer, x, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        # 미분 계산\n",
    "        predictions = model(x, training=True)\n",
    "        loss1 = margin_loss(labels, predictions)\n",
    "        loss2 = MeanSquaredError()(labels, predictions)\n",
    "        \n",
    "        loss = loss1*1. + loss2*0.392\n",
    "        \n",
    "    grad = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grad, model.trainable_variables))     # 신경망 파라미터 업데이트\n",
    "    \n",
    "    acc = tf.keras.metrics.CategoricalAccuracy()\n",
    "    acc.update_state(labels, predictions)\n",
    "    accuracy = acc.result().numpy()\n",
    "    \n",
    "    return loss, accuracy*100\n",
    "\n",
    "def test_step(model, x, labels):\n",
    "    predictions = model(x)\n",
    "    loss1 = margin_loss(labels, predictions)\n",
    "    loss2 = MeanSquaredError()(labels, predictions)\n",
    "    loss = loss1*1. + loss2*0.392\n",
    "    \n",
    "    acc = tf.keras.metrics.CategoricalAccuracy()\n",
    "    acc.update_state(labels, predictions)\n",
    "    accuracy = acc.result().numpy()\n",
    "    \n",
    "    return loss, accuracy*100, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "with open(f'{DATA_ROOT}/{DATA_PATH}.npy', 'rb') as f:\n",
    "    x = np.load(f)\n",
    "    y = np.load(f)\n",
    "\n",
    "y = to_categorical(y,num_classes=len(CLASS_LABELS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE_DECAY_PARAMETERS = -0.15\n",
    "LEARNING_RATE_DECAY_STRATPOINT = 50\n",
    "LEARNING_RATE_DECAY_STEP = 20\n",
    "\n",
    "\n",
    "def scheduler(epoch, lr):\n",
    "    if epoch < LEARNING_RATE_DECAY_STRATPOINT:\n",
    "        return lr\n",
    "    else:\n",
    "        if epoch % LEARNING_RATE_DECAY_STEP == 0:\n",
    "            lr = lr * tf.math.exp(LEARNING_RATE_DECAY_PARAMETERS)\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Smooth label operation\n",
    "def smooth_labels(labels, factor=0.1):\n",
    "    \"\"\"\n",
    "        smooth the labels\n",
    "        returned the smoothed labels\n",
    "    \"\"\"\n",
    "    labels *= (1 - factor)\n",
    "    labels += (factor / labels.shape[1])\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from discord_notice import start, end\n",
    "# start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import tensorflow_addons as tfa\n",
    "from keras.models import load_model\n",
    "\n",
    "emotions_groundtruth_list = np.array([])\n",
    "predicted_emotions_list = np.array([])\n",
    "\n",
    "fold_acc = []\n",
    "\n",
    "kfold = KFold(n_splits=k, shuffle=True, random_state=98)\n",
    "\n",
    "for i, (train, test) in tqdm(enumerate(kfold.split(x, y)), desc=f'Training {k}-Fold.....'):\n",
    "    save_path = f'Models/{DATA_PATH}'\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    h5_path = f'{save_path}/{model_name}_{i}-fold_.h5'\n",
    "    \n",
    "    x_train, y_train = x[train], y[train]\n",
    "    y_train = smooth_labels(y[train], 0.1)\n",
    "    \n",
    "    x_test, y_test = x[test], y[test]\n",
    "    \n",
    "    x_train = tf.expand_dims(x_train, axis=-1)\n",
    "    x_test = tf.expand_dims(x_test, axis=-1)\n",
    "    \n",
    "    shape = x_train.shape[1:]\n",
    "    \n",
    "    optimizer = Adam(learning_rate=learning_rate, beta_1=beta_1, beta_2=beta_2, epsilon=epsilon)\n",
    "    \n",
    "    model = Model(len(CLASS_LABELS))\n",
    "    \n",
    "    best_test_loss = 0x3f3f3f\n",
    "    best_test_acc = -1\n",
    "    best_test_f1 = -1\n",
    "    \n",
    "    epoch_losses = []\n",
    "    valid_losses = []\n",
    "    \n",
    "    batch_train = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(2022).batch(BATCH)\n",
    "    batch_test = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(BATCH)\n",
    "    for epoch in tqdm(range(EPOCHS), desc=f'Fold-{i+1}'):\n",
    "\n",
    "        train_loss, train_acc = [], []\n",
    "        for features, labels in batch_train:\n",
    "            loss, acc = train_step(model, optimizer, features, labels)\n",
    "            train_loss.append(loss)\n",
    "            train_acc.append(acc)\n",
    "            \n",
    "        test_loss, test_acc, f1s = [], [], []\n",
    "        for features, labels in batch_test:\n",
    "            loss, acc, pred = test_step(model, features, labels)\n",
    "            test_loss.append(loss)\n",
    "            test_acc.append(acc)\n",
    "            \n",
    "            f1_metric = tfa.metrics.F1Score(num_classes=len(CLASS_LABELS), average='weighted')\n",
    "            f1_metric.update_state(labels, pred)\n",
    "            f1 = f1_metric.result().numpy()\n",
    "            f1s.append(f1)\n",
    "            \n",
    "        \n",
    "        epoch_loss = sum(train_loss)/len(train_loss)\n",
    "        epoch_acc = sum(train_acc)/len(train_acc)\n",
    "        val_loss = sum(test_loss)/len(test_loss)\n",
    "        val_acc = sum(test_acc)/len(test_acc)\n",
    "        f1_score = sum(f1s)/len(f1s)\n",
    "        \n",
    "        epoch_losses.append(epoch_loss)\n",
    "        valid_losses.append(val_loss)\n",
    "        \n",
    "        cur_lr = K.eval(optimizer.lr)\n",
    "        print(f'{epoch+1}/{EPOCHS} lr={cur_lr:.5f} - loss:{epoch_loss:.3f}, acc:{epoch_acc:.3f}, val_loss:{val_loss:.3f}, val_acc:{val_acc:.3f}')\n",
    "        print(f'Best loss:{best_test_loss:.3f}, Best accuracy:{best_test_acc:.3f}, Best F1-score:{best_test_f1:.3f}')\n",
    "        \n",
    "        set_lr = scheduler(epoch, K.eval(optimizer.lr))\n",
    "        K.set_value(optimizer.learning_rate, set_lr)\n",
    "        \n",
    "        if best_test_acc < val_acc:\n",
    "            best_test_acc = val_acc\n",
    "            best_test_loss = val_loss\n",
    "            best_test_f1 = f1_score\n",
    "            model.save_weights(h5_path)\n",
    "            \n",
    "            \n",
    "    model = Model(len(CLASS_LABELS))\n",
    "    model.build(input_shape=x_train.shape)\n",
    "    model.load_weights(h5_path)\n",
    "    \n",
    "    for features, labels in batch_test:\n",
    "        best_pred = model(features, training=False)\n",
    "        emotions_groundtruth_list = np.append(emotions_groundtruth_list, np.argmax(labels, axis=1))\n",
    "        predicted_emotions_list = np.append(predicted_emotions_list, np.argmax(best_pred, axis=1))\n",
    "    \n",
    "    \n",
    "    print(f'[*] Done - acc:{best_test_acc:.3f}')\n",
    "    \n",
    "    plt.title(f'{i+1}-fold Loss Curve - Best acc:{best_test_acc:.3f}, Best loss:{best_test_loss:.3f}')\n",
    "    plt.ylabel('Loss', fontsize=16)\n",
    "    plt.xlabel('Epoch', fontsize=16)\n",
    "    plt.plot(epoch_losses[:],'b')\n",
    "    plt.plot(valid_losses[:],'r')\n",
    "    plt.legend(['Training loss','Validation loss'])\n",
    "\n",
    "    \n",
    "    save_fig_path = f'Fig/{DATA_PATH}/training/{model_name}'\n",
    "    os.makedirs(save_fig_path, exist_ok=True)\n",
    "    plt.savefig(f'{save_fig_path}/{i+1}-fold.PNG')\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    fold_acc.append(best_test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'max:{max(fold_acc)}, min:{min(fold_acc)}, average:{sum(fold_acc)/len(fold_acc)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('always')\n",
    "\n",
    "Report = classification_report(emotions_groundtruth_list, predicted_emotions_list)\n",
    "\n",
    "os.makedirs(f'Results/{DATA_PATH}', exist_ok=True)\n",
    "report_path = f'Results/{DATA_PATH}/{model_name}_{feature_name}_{k}-fold_nomalize.txt'\n",
    "\n",
    "with open(report_path, \"w\") as f:\n",
    "    f.write(Report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "\n",
    "emotion_names = CLASS_LABELS\n",
    "\n",
    "\n",
    "# build confusion matrix and normalized confusion matrix\n",
    "conf_matrix = confusion_matrix(emotions_groundtruth_list, predicted_emotions_list)\n",
    "conf_matrix_norm = confusion_matrix(emotions_groundtruth_list, predicted_emotions_list,normalize='true')\n",
    "\n",
    "# make a confusion matrix with labels using a DataFrame\n",
    "confmatrix_df = pd.DataFrame(conf_matrix, index=emotion_names, columns=emotion_names)\n",
    "confmatrix_df_norm = pd.DataFrame(conf_matrix_norm, index=emotion_names, columns=emotion_names)\n",
    "\n",
    "# plot confusion matrices\n",
    "plt.figure(figsize=(16,6))\n",
    "sn.set(font_scale=1.8) # emotion label and title size\n",
    "plt.subplot(1,2,1)\n",
    "plt.title('Confusion Matrix')\n",
    "sn.heatmap(confmatrix_df, annot=True, annot_kws={\"size\": 13}, fmt='g') #annot_kws is value font\n",
    "plt.subplot(1,2,2)\n",
    "plt.title('Normalized Confusion Matrix')\n",
    "sn.heatmap(confmatrix_df_norm, annot=True, annot_kws={\"size\": 13}) #annot_kws is value font\n",
    "plt.savefig(f'Results/{DATA_PATH}/{model_name}_{feature_name}_{k}-fold_confmatrix.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_metric_calc(conf_matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "8cc79f3bff38b9826e331232bfe618f732509f3c8555218b497f1264fcaa8b42"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
